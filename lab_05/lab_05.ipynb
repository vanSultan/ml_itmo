{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.\tDownload Alice in Wonderland by Lewis Carroll from Project Gutenberg's website \n",
    "    http://www.gutenberg.org/files/11/11-0.txt\n",
    "2.\tPerform any necessary preprocessing on the text, including converting to lower case, \n",
    "    removing stop words, numbers / non-alphabetic characters, lemmatization.\n",
    "3.\tFind Top 10 most important (for example, in terms of TF-IDF metric) words \n",
    "    from each chapter in the text (not \"Alice\"); how would you name each chapter \n",
    "    according to the identified tokens?\n",
    "4.\tFind the Top 10 most used verbs in sentences with Alice. What does Alice do most often?\n",
    "5.\t*(not necessary) Find Top 100 most used verbs in sentences with Alice. \n",
    "    Get word vectors using a pre-trained word2vec model and visualize them. \n",
    "    Compare the words using embeddings."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from os import listdir"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sultan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sultan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sultan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Sultan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load text into memory\n",
    "with open(\"./11-0.txt\", \"r\", encoding=\"utf8\") as f_src:\n",
    "    text = f_src.read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Clean text\n",
    "def clean_text(txt):\n",
    "    tokens = txt.split()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    tokens = [word for word in tokens if len(word) > 3]\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Turn a text into clean tokens\n",
    "words = clean_text(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "lem_words = [wordnet_lemmatizer.lemmatize(word, pos='v') for word in words]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['project', 'adventures', 'wonderland', 'lewis', 'carroll', 'this', 'ebook', 'anyone', 'anywhere', 'cost']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Lowercase\n",
    "lem_words = [word.lower() for word in lem_words] \n",
    "print(lem_words[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Total count of chapters: 12\n",
      "First 3 words per chapter:\n",
      "['down', 'rabbithole', 'alice']\n",
      "['pool', 'tears', 'cry']\n",
      "['caucusrace', 'long', 'tale']\n",
      "['rabbit', 'sends', 'little']\n",
      "['advice', 'caterpillar', 'caterpillar']\n",
      "['pepper', 'minute', 'stand']\n",
      "['teaparty', 'there', 'table']\n",
      "['viii', 'croquetground', 'large']\n",
      "['mock', 'story', 'think']\n",
      "['lobster', 'quadrille', 'mock']\n",
      "['stole', 'tarts', 'king']\n",
      "['evidence', 'cry', 'alice']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Chapters\n",
    "chapters, tmp_chap = list(), list()\n",
    "for word in lem_words:\n",
    "    if word == \"chapter\":\n",
    "        tmp_chap = list() \n",
    "        chapters.append(tmp_chap)\n",
    "    else:\n",
    "        tmp_chap.append(word)\n",
    "\n",
    "print(f\"Total count of chapters: {len(chapters)}\")\n",
    "\n",
    "print(\"First 3 words per chapter:\")    \n",
    "for i in range(len(chapters)):\n",
    "    print(chapters[i][0:3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# TF\n",
    "def get_tf(word, f_text):\n",
    "    tf_text = Counter(f_text)\n",
    "    tf_text[word] = tf_text[word] / float(len(f_text))\n",
    "        \n",
    "    return tf_text[word]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# IDF\n",
    "def get_idf(word, chaps):\n",
    "    count = sum([1.0 for chap in chaps if word in chap])\n",
    "    if count != 0:\n",
    "        return math.log(len(chaps) / count)\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Note\n",
    "\n",
    "I would name them by the first three words found."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Chapter 1\n",
      "            0        1\n",
      "0      either  0.01011\n",
      "1        down  0.00906\n",
      "2  rabbithole  0.00906\n",
      "3        dark  0.00906\n",
      "4         bat  0.00906\n",
      "5      candle  0.00906\n",
      "6      bottle  0.00871\n",
      "7        fall  0.00745\n",
      "8        fell  0.00674\n",
      "9        burn  0.00653\n",
      "\n",
      "Chapter 2\n",
      "          0        1\n",
      "0     mouse  0.01423\n",
      "1      pool  0.01386\n",
      "2     mabel  0.01242\n",
      "3      swim  0.01213\n",
      "4    gloves  0.00896\n",
      "5       cat  0.00866\n",
      "6      four  0.00693\n",
      "7   capital  0.00672\n",
      "8  ringlets  0.00621\n",
      "9     andoh  0.00621\n",
      "\n",
      "Chapter 3\n",
      "            0        1\n",
      "0        dodo  0.03248\n",
      "1       mouse  0.02513\n",
      "2        lory  0.01624\n",
      "3       cause  0.01083\n",
      "4        bird  0.00996\n",
      "5        ring  0.00751\n",
      "6      morcar  0.00751\n",
      "7       earls  0.00751\n",
      "8      mercia  0.00751\n",
      "9  archbishop  0.00751\n",
      "\n",
      "Chapter 4\n",
      "         0        1\n",
      "0    puppy  0.01501\n",
      "1   window  0.01251\n",
      "2   gloves  0.01083\n",
      "3   bottle  0.01083\n",
      "4  chimney  0.01001\n",
      "5     mary  0.00751\n",
      "6     rush  0.00751\n",
      "7     bark  0.00751\n",
      "8     pair  0.00722\n",
      "9    stick  0.00722\n",
      "\n",
      "Chapter 5\n",
      "             0        1\n",
      "0  caterpillar  0.04176\n",
      "1       pigeon  0.03593\n",
      "2      serpent  0.01198\n",
      "3          egg  0.01198\n",
      "4       father  0.01079\n",
      "5        youth  0.00898\n",
      "6     serpents  0.00898\n",
      "7       hookah  0.00863\n",
      "8         size  0.00794\n",
      "9         what  0.00668\n",
      "\n",
      "Chapter 6\n",
      "         0        1\n",
      "0  footman  0.02583\n",
      "1     baby  0.01863\n",
      "2  duchess  0.01274\n",
      "3   sneeze  0.01153\n",
      "4     howl  0.01033\n",
      "5    grunt  0.01033\n",
      "6     cook  0.01009\n",
      "7     grin  0.01009\n",
      "8   livery  0.00775\n",
      "9    nurse  0.00745\n",
      "\n",
      "Chapter 7\n",
      "          0        1\n",
      "0    hatter  0.05070\n",
      "1  dormouse  0.04915\n",
      "2      hare  0.02637\n",
      "3     march  0.02101\n",
      "4   twinkle  0.01024\n",
      "5     civil  0.00852\n",
      "6    asleep  0.00792\n",
      "7      draw  0.00753\n",
      "8     pinch  0.00614\n",
      "9    bottom  0.00614\n",
      "\n",
      "Chapter 8\n",
      "             0        1\n",
      "0        queen  0.02077\n",
      "1    gardeners  0.02054\n",
      "2     hedgehog  0.01797\n",
      "3         five  0.01296\n",
      "4      soldier  0.01289\n",
      "5  executioner  0.01284\n",
      "6         king  0.01135\n",
      "7     rosetree  0.01027\n",
      "8   procession  0.01027\n",
      "9        paint  0.00770\n",
      "\n",
      "Chapter 9\n",
      "         0        1\n",
      "0     mock  0.04162\n",
      "1   turtle  0.04002\n",
      "2  gryphon  0.02537\n",
      "3    moral  0.02009\n",
      "4  duchess  0.01719\n",
      "5    queen  0.01041\n",
      "6     chin  0.00640\n",
      "7     sigh  0.00634\n",
      "8   pepper  0.00621\n",
      "9   school  0.00621\n",
      "\n",
      "Chapter 10\n",
      "             0        1\n",
      "0       turtle  0.05212\n",
      "1         mock  0.04864\n",
      "2      gryphon  0.04268\n",
      "3        dance  0.03737\n",
      "4      lobster  0.01868\n",
      "5     lobsters  0.01868\n",
      "6       soooop  0.01868\n",
      "7    beautiful  0.01737\n",
      "8         soup  0.01563\n",
      "9  beauootiful  0.01246\n",
      "\n",
      "Chapter 11\n",
      "          0        1\n",
      "0      king  0.04069\n",
      "1    hatter  0.03950\n",
      "2     court  0.03318\n",
      "3  dormouse  0.03063\n",
      "4   witness  0.01770\n",
      "5   officer  0.01770\n",
      "6     tarts  0.01276\n",
      "7   trumpet  0.01062\n",
      "8    jurors  0.01062\n",
      "9    teacup  0.01062\n",
      "\n",
      "Chapter 12\n",
      "         0        1\n",
      "0     king  0.02930\n",
      "1    dream  0.01520\n",
      "2     jury  0.01512\n",
      "3   sister  0.01303\n",
      "4  jurymen  0.01205\n",
      "5    write  0.01061\n",
      "6  jurybox  0.00904\n",
      "7     sign  0.00904\n",
      "8     slat  0.00869\n",
      "9    queen  0.00756\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Top-10 TF-IDF in chapters\n",
    "chapters_list = list()\n",
    "for chapter in chapters:\n",
    "    vocab_chapters = Counter()\n",
    "    for word in chapter:\n",
    "        if word != \"alice\":\n",
    "            vocab_chapters[word] = get_tf(word, chapter) * get_idf(word, chapters)\n",
    "            vocab_chapters[word] = round(vocab_chapters[word], 5)\n",
    "    chapters_list.append(vocab_chapters)\n",
    "        \n",
    "for chapter in chapters_list:\n",
    "    print(\"Chapter \" + str(chapters_list.index(chapter) + 1))\n",
    "    print(pd.DataFrame(chapter.most_common(10)))\n",
    "    print()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Note\n",
    "\n",
    "Alice most often says something, goes somewhere and thinks about something."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "    Verb  Count\n0    say     59\n1     go     32\n2  think     25\n3   take     18\n4   keep     12\n5   find     11\n6   tell     10\n7  begin      9\n8   make      8\n9    get      8",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Verb</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>say</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>go</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>think</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>take</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>keep</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>find</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>tell</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>begin</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>make</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>get</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "# Verbs with 'Alice'\n",
    "vocab_verbs = Counter()\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "for sentence in sentences:\n",
    "    sentence_words = clean_text(sentence)\n",
    "    sentence_words = [wordnet_lemmatizer.lemmatize(w, pos='v') for w in sentence_words]\n",
    "    sentence_words = [w.lower() for w in sentence_words]\n",
    "    if \"alice\" in sentence_words:\n",
    "        sentence_words = nltk.pos_tag(sentence_words)\n",
    "        for word, pos_tag in sentence_words:\n",
    "            if pos_tag == \"VB\":\n",
    "                vocab_verbs[word] += 1 \n",
    "pd.DataFrame(data=vocab_verbs.most_common(10), columns=[\"Verb\", \"Count\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}